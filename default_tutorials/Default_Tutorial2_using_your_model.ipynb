{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bddd444",
   "metadata": {},
   "source": [
    "## PyBEAM Tutorial 2: Using your model.\n",
    "\n",
    "In this tutorial, we discuss how to use the model structure discussed in Tutorial 1. If you have not done so already, go to the Tutorial 1 notebook to learn about how to build a model.\n",
    "\n",
    "Once you have done this, import PyBEAM's default sub-module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyBEAM's default module\n",
    "import pybeam.default as pbd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb2008",
   "metadata": {},
   "source": [
    "We first create the 'base' model discussed in Tutorial 1 with no additional features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ef6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "model = {'type' : 'base',  # model type ('base' or 'ugm')\n",
    "        'sigma' : 1.0,     # sets sigma, the scaling parameter\n",
    "    'threshold' : 'fixed', # sets threshold type (fixed, linear, exponential, or weibull)\n",
    "      'leakage' : False,   # if True, drift rate has leaky integration\n",
    "        'delay' : False,   # if True, decision threshold motion is delayed\n",
    "'contamination' : False}   # if True, uniform contamination added to model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42846d6d",
   "metadata": {},
   "source": [
    "After specifying the model, it is helpful to run PyBEAM's parse_model function. It accepts your model dictionary as an input, and outputs the parameters corresponding to that model. This does two things. First, it checks if you have defined the model you want. Secondly, if you are unsure what parameters a model calls for, it tells you what parameters need to be input into future functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e87381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs which parameters your model uses\n",
    "pbd.parse_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a5995",
   "metadata": {},
   "source": [
    "Now that we have defined our model and checked that is uses the parameters we desire, we now introduce functions PyBEAM implements that you can use to test your model.\n",
    "\n",
    "The first is simulate_data, a function which simulates data from your model. This requires at least three inputs: N_sims, model, and phi. The first, N_sims, sets how many data points are generated. The second, model, requires the model dictionary defined above.\n",
    "\n",
    "The last, phi, is a dictionary containing the parameters (as keys) and their values (as the key's values). Per the parse_model function, this dictionary requires four keys: 't_nd', 'w', 'mu', and 'a'. The values corresponding to these keys are the parameter's values.\n",
    "\n",
    "Two optional inputs are also available for this funtion. The first, seed, allows you to set a random generator seed so that you can reproduce your data set. The second, dt, allows for modification of the simulation function's time step (by default, dt = 0.0001).\n",
    "\n",
    "This functions outputs a dictionary containing two keys: 'rt_upper' and 'rt_lower'. These correspond to the simulated reaction time data sets for the upper and lower decision thresholds, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0036e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters for model\n",
    "phi = {'t_nd' : 0.25, # non-decision time\n",
    "          'w' : 0.5,  # relative start point\n",
    "         'mu' : 1.0,  # drift rate\n",
    "          'a' : 0.5}  # decision threshold location\n",
    "\n",
    "# simulate data from the model\n",
    "rt = pbd.simulate_model(N_sims = 500,   # number of data points to simulate\n",
    "                         model = model, # dictionary containing model information\n",
    "                           phi = phi)   # parameters used to simulate data\n",
    "\n",
    "rt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d68447",
   "metadata": {},
   "source": [
    "The next function we introduce is model_rt. model_rt allows takes the input model and calculates its likelihood function (i.e. the model's predicted rt distribution). It has two required inputs: model and phi. These are the same inputs as those used by the simulate_model function. \n",
    "\n",
    "It also has two optional inputs, x_res and t_res, which allow modification of the spatial and time stepping resolution. In general, these need not be touched (see default functions description file for more info).\n",
    "\n",
    "This function outputs a dictionary containing three keys: 'time', 'model_rt_upper', and 'model_rt_lower'. These contain the time, upper threshold likelihood function, and lower threshold likelihood function, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc35e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mrt = pbd.model_rt(model = model,\n",
    "                     phi = phi)\n",
    "\n",
    "mrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a7409",
   "metadata": {},
   "source": [
    "The next function we introduce is model_loglike. model_loglike allows takes the input model and and a dataset and calculates the loglikelihood of the data (based on the model's likelihood function). It has three required inputs: model, phi, and rt. model and phi are the same inputs as those used by the simulate_model and model_rt functions.\n",
    "\n",
    "The input rt requires a dictionary containing the reaction time data you want to find the loglikelihood of. The dictionary must look the same as that output by simulate_model. It should have two keys, 'rt_upper' and 'rt_lower', whose values are lists/numpy arrays which the rt data for the upper and lower decision thresholds, respectively.\n",
    "\n",
    "It also has two optional inputs, x_res and t_res, which allow modification of the spatial and time stepping resolution. In general, these need not be touched (see default functions description file for more info).\n",
    "\n",
    "This function outputs a number corresponding to the data's loglikelihood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pbd.model_loglike(model = model,\n",
    "                         phi = phi,\n",
    "                          rt = rt)\n",
    "\n",
    "ll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487222c",
   "metadata": {},
   "source": [
    "PyBEAM also contains a plotting utility. It generates a figure which overlays the model likelihood over rt data. It accepts the same model and phi inputs as the simulate_model function, but also requires an input of the rt. This is the same input as for the model_loglike function. Input rt must be a dictionary containing two keys, 'rt_upper' and 'rt_lower'. The values for these keys are lists/numpy arrays which contain the rt data for the upper and lower decision thresholds, respectively.\n",
    "\n",
    "The function has two three additional optional inputs: x_res, t_res, and bins. x_res and t_res are discussed further in the functions description notebook, but you should never need to change their default settings. bins sets the amount of histogram bins to use for the rt data. Though the default setting often is fine, it sometimes fails to choose the proper bin amount and may need to be manually input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data and model likelihood function\n",
    "pbd.plot_rt(model = model, # dictionary containing model information \n",
    "              phi = phi,   # parameters used for model rt distribution\n",
    "               rt = rt);   # dictionary of simulated rt data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cebf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
