{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4b02f6",
   "metadata": {},
   "source": [
    "# Custom Tutorial 3: Parameter inference\n",
    "\n",
    "In this tutorial, we demonstrate how to fit your custom model to data. The process is nearly identical to that of the precoded sub-module, so we will principally focus on what's different between the precoded and custom versions here. Refer to Default Tutorial 3 for use details.\n",
    "\n",
    "The specific model we will use for this example is the urgency gating model with time depenedent drift discussed in PyBEAM's publication, referred to as UGM_flip. This model is also available in PyBEAM's precoded sub-module, with Tutorial 1f on github discussing its use. In this model, the drift rate flips from positive to negative at time t_flip. The model files for this example are on PyBEAM's github under the folder UGM_flip.\n",
    "\n",
    "As before, import PyBEAM's custom sub-module. We additionally import matplotlib for plotting and os to check that our directory is input correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b292f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyBEAM's custom module\n",
    "import pybeam.custom as pbc\n",
    "\n",
    "# also import pyplot to modify figure axes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import os to check if you have input your model directory correctly\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b410073",
   "metadata": {},
   "source": [
    "Next, as in Custom Tutorial 2, we need to tell the program where your model is located at. To do this, create a string containing the FULL directory name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086192fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory containing your model goes here\n",
    "model_dir = '/Users/matthewmurrow/Documents/phd_research/pybeam/ugm_flip'\n",
    "\n",
    "# for windows computers, r before the directory is necessary\n",
    "# model_dir = r''\n",
    "\n",
    "# check if directory is input properly\n",
    "os.path.isdir(model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e8132",
   "metadata": {},
   "source": [
    "We next call functions_test to make sure that our model is acting as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary containing model parameters\n",
    "phi = {'phi[0]' : 0.25, # tnd: non-decision time\n",
    "       'phi[1]' : 0.5,  # w: relative start point\n",
    "       'phi[2]' : 1.0,  # mu: drift rate\n",
    "       'phi[3]' : 3.0,  # l: leakage rate\n",
    "       'phi[4]' : 2.0,  # k: urgency ratio\n",
    "       'phi[5]' : 0.5,  # t0: time for first drift rate flip\n",
    "       'phi[6]' : 1.0,  # sigma: model scale\n",
    "       'phi[7]' : 1.0}  # b: threshold location\n",
    "    \n",
    "# run function to test if model functions are input properly\n",
    "pbc.functions_test(model_dir = model_dir, # string containing directory name where your model files are\n",
    "                         phi = phi,       # dictionary of model parameters\n",
    "                           x = 0.0,       # accumulator state\n",
    "                           t = 1.0)       # time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf47e2f",
   "metadata": {},
   "source": [
    "Next, we simulate two data sets. These encode two different conditions: a low caution and high caution condition encoded in lower and higher threshold locations, respectively.\n",
    "\n",
    "To do this, we first set the parameters for each data set. We follow the same process as in Custom Tutorial 2, where we generate a dictionary with keys corresponding to the parameters defined in your model file, and values giving the value of that parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for data set 0\n",
    "phi0 = {'phi[0]' : 0.25,  # tnd: non-decision time\n",
    "        'phi[1]' : 0.5,   # w: relative start point\n",
    "        'phi[2]' : 1.0,   # mu: drift rate\n",
    "        'phi[3]' : 3.0,   # l: leakage rate\n",
    "        'phi[4]' : 2.0,   # k: urgency ratio\n",
    "        'phi[5]' : 0.5,   # t_flip: time for the drift rate flip\n",
    "        'phi[6]' : 1.0,   # sigma: model scale\n",
    "        'phi[7]' : 1.0}   # b: threshold location\n",
    "\n",
    "# simulate data for parameter set 0\n",
    "rt0 = pbc.simulate(model_dir = model_dir,\n",
    "                      N_sims = 500,\n",
    "                         phi = phi0)\n",
    "\n",
    "# plot data set 0\n",
    "pbc.plot_rt(model_dir = model_dir,\n",
    "                  phi = phi0,\n",
    "                   rt = rt0,\n",
    "               rt_max = 1.5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6eaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for data set 1\n",
    "phi1 = {'phi[0]' : 0.25,  # tnd: non-decision time\n",
    "        'phi[1]' : 0.5,   # w: relative start point\n",
    "        'phi[2]' : 1.0,   # mu: drift rate\n",
    "        'phi[3]' : 3.0,   # l: leakage rate\n",
    "        'phi[4]' : 2.0,   # k: urgency ratio\n",
    "        'phi[5]' : 0.5,   # t_flip: time for the drift rate flip\n",
    "        'phi[6]' : 1.0,   # sigma: model scale\n",
    "        'phi[7]' : 1.5}   # b: threshold location\n",
    "\n",
    "# simulate data for parameter set 1\n",
    "rt1 = pbc.simulate(model_dir = model_dir,\n",
    "                      N_sims = 500,\n",
    "                         phi = phi1)\n",
    "\n",
    "# plot data set 1\n",
    "pbc.plot_rt(model_dir = model_dir,\n",
    "                  phi = phi1,\n",
    "                   rt = rt1,\n",
    "               rt_max = 2.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4c51d",
   "metadata": {},
   "source": [
    "Next, we call the parameter inference function. To do this, we follow the same procedure as in Precoded Tutorial 3. First, we define our bank of priors. The key names an be anything, so we give them a name convenient for our situation i.e. the prior for phi[0] is pphi[0], and so on. The values for each key are the priors themselves written in PyMC syntax (made into strings). In this case, we use PyMC's uniform priors, with the syntax:\n",
    "\n",
    "    Uniform( \"prior name\" , lower = (lower bound of prior) ,upper = (upper bound of prior) ) \n",
    "\n",
    "Other available PyMC priors are located on the PyMC website at the following link:\n",
    "\n",
    "    https://www.pymc.io/projects/docs/en/stable/api/distributions.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bank of priors\n",
    "p = {'pphi[0]' : 'Uniform(\"t_nd\", lower = 0.0, upper = 0.75)',   # non-decision time prior\n",
    "     'pphi[1]' : 'Uniform(\"w\", lower = 0.3, upper = 0.7)',       # relative start point prior\n",
    "     'pphi[2]' : 'Uniform(\"mu\", lower = -5.0, upper = 5.0)',     # drift rate prior\n",
    "     'pphi[3]' : 'Uniform(\"l\", lower = 0.0, upper = 10.0)',      # leakage rate prior\n",
    "     'pphi[4]' : 'Uniform(\"k\", lower = 0.0, upper = 10.0)',      # urgency rate prior\n",
    "     'pphi[5]' : 'Uniform(\"t_flip\", lower = 0.01, upper = 1.0)', # first drift flip time\n",
    "     'pphi[6]' : 1.0,                                            # scaling parameter\n",
    "     'pphi[7]0' : 'Uniform(\"a0\", lower = 0.25, upper = 3.0)',    # decision threshold prior 0\n",
    "     'pphi[7]1' : 'Uniform(\"a1\", lower = 0.25, upper = 3.0)'}    # decision threshold prior 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47749e9",
   "metadata": {},
   "source": [
    "We next define two dictionaries which set which priors are associated with what parameters and which data set for each condition. This dictionary contains keys corresponding to each parameter. For the UGM_flip model we defined, we will have keys of 'phi[0]', 'phi[1]', ... , 'phi[7]', since the model has 8 parameters. The values of these keys indicate which priors from the prior dictionary are associated with each parameter. So, for example, parameter 'phi[0]' has the prior associated with prior key 'pphi[0]'.\n",
    "\n",
    "In addition to the parameters, a key 'rt' is required. This key contains the data you would like to fit. This data set must be in the same form as that output by the simulate model function. It must have two keys, 'rt_upper' and 'rt_lower'. The values for these keys must be 1D lists/numpy arrays containing the reaction time data for the two choices (crossing the upper and lower decision thresholds, respectively).\n",
    "\n",
    "This dictionary is then loaded into one last dictionary which will be input into the inference function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define condition 0 dictionary\n",
    "c0 = {'rt' : rt0,\n",
    "  'phi[0]' : 'pphi[0]', \n",
    "  'phi[1]' : 'pphi[1]',  \n",
    "  'phi[2]' : 'pphi[2]', \n",
    "  'phi[3]' : 'pphi[3]',  \n",
    "  'phi[4]' : 'pphi[4]',  \n",
    "  'phi[5]' : 'pphi[5]',\n",
    "  'phi[6]' : 'pphi[6]', \n",
    "  'phi[7]' : 'pphi[7]0'}\n",
    "\n",
    "# define condition 1 dictionary\n",
    "c1 = {'rt' : rt1,\n",
    "  'phi[0]' : 'pphi[0]', \n",
    "  'phi[1]' : 'pphi[1]',  \n",
    "  'phi[2]' : 'pphi[2]', \n",
    "  'phi[3]' : 'pphi[3]',  \n",
    "  'phi[4]' : 'pphi[4]',  \n",
    "  'phi[5]' : 'pphi[5]',\n",
    "  'phi[6]' : 'pphi[6]', \n",
    "  'phi[7]' : 'pphi[7]1'}\n",
    " \n",
    "cond = {0 : c0, 1 : c1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0bfd01",
   "metadata": {},
   "source": [
    "We now run PyBEAM's parameter inference program, inference. This takes the input data and priors and outputs posteriors for each parameter. It requires inputs of the model directory, the prior dictionary, the conditions dictionary, chains (how many mcmc chains you want), cores (how many cpu cores to run those chains on), and file name (a string containing the file name to save the posteriors to).\n",
    "\n",
    "This function has a few additional optional inputs that generally are not needed. These include resolution settings and MCMC solvers different than the default. These are disucssed fully in the \"precoded_functions\" notebook in folder Tutorials on the PyBEAM github.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bccafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = pbc.inference(model_dir = model_dir, # specify model directory\n",
    "                         priors = p,         # dictionary of priors\n",
    "                     conditions = cond,      # conditions dictionary\n",
    "                        samples = 50000,     # MCMC samples\n",
    "                         chains = 3,         # MCMC chains \n",
    "                          cores = 3,         # CPU cores to run MCMC chains on\n",
    "                      file_name = 'custom')  # output file name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323734e9",
   "metadata": {},
   "source": [
    "PyBEAM contains two more useful functions. The first, plot_idata, plots the posteriors output by the program. The second, summary, provides posterior summary statistics. They both accept input of the file name, in addition to a 'burnin' which sets how many of the samples need to be thrown out from the beginning.\n",
    "\n",
    "Both functions are from the arviz library, so see the arviz/pymc documentation for more information about them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posteriors\n",
    "pbc.plot_idata(file_name = 'custom', burnin = 25000);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e519ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of posteriors\n",
    "pbc.summary(file_name = 'custom', burnin = 25000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4d795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5_env",
   "language": "python",
   "name": "pymc5_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
