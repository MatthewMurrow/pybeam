{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c881a8ab",
   "metadata": {},
   "source": [
    "# Fitting Evans2020 Experiment 1 data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fceac8",
   "metadata": {},
   "source": [
    "In this notebook, we use PyBEAM's precoded sub-moudule to fit a Weibull changing threhsolds model to Evans2020's data. The citation for their publication is below:\n",
    "\n",
    "    Evans, N. J., Hawkins, G. E., & Brown, S. D. (2020). The role of passing time in decision-making. Journal\n",
    "    of Experimental Psychology: Learning, Memory, and Cognition, 46(2), 316â€“326. doi: 10.1037/xlm0000725. \n",
    "    \n",
    "We specifically look at the Experiment 1 data from their publication. In that experiment, participants were given a random dot coherence task with four coherence conditions: 0%, 5%, 10%, and 40%. Reward rate was emphasized, with particpants instructed to maximize the number of correct decisions. Participants had a fixed time of 5 seconds in which to make the choice.\n",
    "\n",
    "In addition to this notebook, three files located on the PyBEAM github are needed for this analysis: parseEvans2020.py, Evans2020_Exp1_data.csv, and Evans2020_Exp1_subjects.csv. We will discuss how they are used below.\n",
    "\n",
    "First, we import PyBEAM's precoded sub-module. Additionally, we import parseEvans2020.py and numpy to handle data importing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85796a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyBEAM\n",
    "import pybeam.precoded as pbp\n",
    "\n",
    "# import script to parse Evans data\n",
    "from parseEvans2020 import subject_rt\n",
    "\n",
    "# import numpy to load Evans data\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c78c46",
   "metadata": {},
   "source": [
    "The next block of code imports and sorts the Evans Experiment 1 data set. We first load the data (Evans2020_Exp1_data.csv) and subject numbers (Evans2020_Exp1_subjects.csv) and place them in arrays. Data contains the participant number, choice made (correct or incorrect), coherence (0%, 5%, 10% or 40%), and reaction time. Subjects contains the list of participants.\n",
    "\n",
    "To sort out the data for a single participant, we call the subject_rt function imported from parseEvans2020.py. It takes as inputs the data array, subjects arrays, the subject number we would like to fit, minimum rt value (filters out data below this value, as done in Evans), and the max rt value (filters out data above this value, as done in Evans).\n",
    "\n",
    "subject_rt outputs a dictionary containing four keys: 'rt0', 'rt5', 'rt10', and 'rt40'. These contain dictionaries holding the reaction time data for each of the four coherence conditions. Each sub-dictionary contains two entries: 'rt_upper' and 'rt_lower'. 'rt_upper' contains an array of rt values corresponding to the correct choice. 'rt_lower' contains an array of values containing the rt values corresponding to an error. It outputs this particular structure becauase is the data structure required by PyBEAM's other functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44442737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rt data from Evans2020 Experiment 1\n",
    "data = np.asarray(np.loadtxt(open(\"Evans2020_Exp1_data.csv\", \"rb\"), delimiter=\",\", skiprows=1))\n",
    "\n",
    "# import subject numbers from Evans2020\n",
    "subjects = np.asarray(np.loadtxt(open(\"Evans2020_Exp1_subjects.csv\", \"rb\"), delimiter=\",\", skiprows=1))\n",
    "\n",
    "# subject to fit model to (from list subjects)\n",
    "subject_number = 31727\n",
    "\n",
    "# filter data below min_rt and above max_rt\n",
    "min_rt = 0.25\n",
    "max_rt = 5.0\n",
    "\n",
    "# file name to save posteriors to\n",
    "file_name = 'subject_' + str(int(subject_number))\n",
    "\n",
    "# return rt for desired subject number\n",
    "rt = subject_rt(subject_number = subject_number, \n",
    "                          data = data, \n",
    "                      subjects = subjects, \n",
    "                        min_rt = min_rt, \n",
    "                        max_rt = max_rt)\n",
    "\n",
    "rt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d862405",
   "metadata": {},
   "source": [
    "Now that we have imported our data, we now define our model. Following Evans, we use an EAM with Weibull thresholds and uniform contamination. If you are unsure how to use the model call out, see Tutorial 1 under \"getting_started\" on the PyBEAM github.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2783f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call changing thresholds model\n",
    "model = pbp.changing_thresholds(contamination = 'uniform')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40508b9",
   "metadata": {},
   "source": [
    "Now that we have defined our model, we can define our priors, conditions, and run the inference program. Since we have four coherences, we will have four model conditions, each with their own unique drift rate prior. Each model condition has its own data set, corresponding to one of the four coherences. Following Evans, we assume that the threshold will collapse completely from its initial location, so we set the collapse parameter, c, to -1 in the priors dictionary. We also assume that the uniform contamination can occur as any time between the min and max rt values, so we set the lower and upper contaminations to be theses values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define priors\n",
    "p = {'ptnd' : 'Uniform(\"tnd\", lower = 0.0, upper = 0.75)',  # prior for non-decision time\n",
    "       'pw' : 'Uniform(\"w\", lower = 0.3, upper = 0.7)',      # prior for relative start\n",
    "     'pmu0' : 'Uniform(\"mu0\", lower = -5.0, upper = 5.0 )',  # drift rate prior for coherence 0%\n",
    "     'pmu5' : 'Uniform(\"mu5\", lower = -5.0, upper = 5.0)',   # drift rate prior for choherence 5%\n",
    "    'pmu10' : 'Uniform(\"mu10\", lower = -5.0, upper = 5.0)',  # drift rate prior for coherence 10%\n",
    "    'pmu40' : 'Uniform(\"mu40\", lower = -5.0, upper = 5.0)',  # drift rate prior for coherence 40%\n",
    "       'pb' : 'Uniform(\"b\", lower = 0.25, upper = 2.0)',     # prior for threshold location\n",
    "    'plamb' : 'Uniform(\"lamb\", lower = -1.0, upper = 2.0)',  # prior for scale parameter\n",
    "   'pkappa' : 'Uniform(\"kappa\", lower = -1.0, upper = 2.0)', # prior for shape parameter\n",
    "        'c' : -1.0,                                          # collapse parameter value\n",
    "       'pg' : 'Uniform(\"g\", lower = 0.0, upper = 0.75)',     # prior for contamination strength\n",
    "       'gl' : min_rt,                                        # uniform contamination lower bound\n",
    "       'gu' : max_rt}                                        # uniform contamination upper bound\n",
    "\n",
    "# model condition for coherence 0%\n",
    "c0 = {'rt' : rt['rt0'],\n",
    "     'tnd' : 'ptnd',\n",
    "       'w' : 'pw',\n",
    "      'mu' : 'pmu0',\n",
    "       'b' : 'pb',\n",
    "    'lamb' : 'plamb',\n",
    "   'kappa' : 'pkappa',\n",
    "       'c' : 'c',\n",
    "       'g' : 'pg',\n",
    "      'gl' : 'gl',\n",
    "      'gu' : 'gu'}\n",
    "\n",
    "# model condition for coherence 5%\n",
    "c5 = {'rt' : rt['rt5'],\n",
    "     'tnd' : 'ptnd',\n",
    "       'w' : 'pw',\n",
    "      'mu' : 'pmu5',\n",
    "       'b' : 'pb',\n",
    "    'lamb' : 'plamb',\n",
    "   'kappa' : 'pkappa',\n",
    "       'c' : 'c',\n",
    "       'g' : 'pg',\n",
    "      'gl' : 'gl',\n",
    "      'gu' : 'gu'}\n",
    "\n",
    "# model condition for coherence 10%\n",
    "c10 = {'rt' : rt['rt10'],\n",
    "       'tnd' : 'ptnd',\n",
    "         'w' : 'pw',\n",
    "        'mu' : 'pmu10',\n",
    "         'b' : 'pb',\n",
    "      'lamb' : 'plamb',\n",
    "     'kappa' : 'pkappa',\n",
    "         'c' : 'c',\n",
    "         'g' : 'pg',\n",
    "        'gl' : 'gl',\n",
    "        'gu' : 'gu'}\n",
    "\n",
    "# model condition for coherence 40%\n",
    "c40 = {'rt' : rt['rt40'],\n",
    "      'tnd' : 'ptnd',\n",
    "        'w' : 'pw',\n",
    "       'mu' : 'pmu40',\n",
    "        'b' : 'pb',\n",
    "     'lamb' : 'plamb',\n",
    "    'kappa' : 'pkappa',\n",
    "        'c' : 'c',\n",
    "        'g' : 'pg',\n",
    "       'gl' : 'gl',\n",
    "       'gu' : 'gu'}\n",
    "\n",
    "# load conditions into dictionary\n",
    "cond = {0 : c0, 1 : c5, 2 : c10, 3 : c40}\n",
    "\n",
    "# run parameter inference\n",
    "idata = pbp.inference(model = model,\n",
    "                     priors = p,\n",
    "                 conditions = cond,\n",
    "                    samples = 50000,\n",
    "                     chains = 3,\n",
    "                      cores = 3,\n",
    "                  file_name = file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb9baf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot posteriors\n",
    "pbp.plot_idata(file_name = file_name, burnin = 25000);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior summary statistics\n",
    "pbp.summary(file_name = file_name, burnin = 25000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62232529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
